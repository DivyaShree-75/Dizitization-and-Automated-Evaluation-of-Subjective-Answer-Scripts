# -*- coding: utf-8 -*-
"""semantic_scoring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ve4r5XVZDV2P_ApXHm44VDDk5uNIC7us
"""

import pandas as pd
import json
import nltk
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
from sklearn.metrics.pairwise import cosine_similarity
from fuzzywuzzy import fuzz

nltk.download('punkt')
nlp = spacy.load("en_core_web_sm")

def compute_tfidf_cosine(text1, text2):
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf_matrix = tfidf.fit_transform([text1, text2])
    return round(float(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]), 3)

def jaccard_similarity(text1, text2):
    set1 = set(text1.lower().split()) - ENGLISH_STOP_WORDS
    set2 = set(text2.lower().split()) - ENGLISH_STOP_WORDS
    if not set1 or not set2:
        return 0.0
    return round(len(set1 & set2) / len(set1 | set2), 3)

def fuzzy_score(text1, text2):
    return fuzz.token_set_ratio(text1, text2)

def relevance_score(tfidf, jaccard, fuzzy):
    return round((tfidf + jaccard + fuzzy / 100) / 3, 3)

def compute_spacy_coherence_score(answer):
    if not isinstance(answer, str) or len(answer.strip()) < 5:
        return 0.1

    try:
        sentences = nltk.sent_tokenize(answer)
        words = nltk.word_tokenize(answer.lower())
        if not sentences or not words:
            return 0.1

        unique_words = set(words)

        sentence_score = min(len(sentences) / 4.0, 1.0)
        avg_sent_len = sum(len(nltk.word_tokenize(s)) for s in sentences) / len(sentences)
        sentence_length_score = 1.0 if 8 <= avg_sent_len <= 25 else 0.5
        structure_score = (sentence_score + sentence_length_score) / 2.0

        lexical_diversity = len(unique_words) / len(words)
        lexical_score = min(lexical_diversity / 0.7, 1.0)

        doc = nlp(answer)
        connectors = [token.text.lower() for token in doc
                      if token.pos_ in ("CCONJ", "SCONJ", "ADV") and token.dep_ in ("mark", "advmod")]
        connector_score = 1.0 if len(connectors) >= 2 else 0.5

        word_count_score = min(len(words) / 100.0, 1.0)

        coherence = (
            0.30 * structure_score +
            0.25 * lexical_score +
            0.25 * connector_score +
            0.20 * word_count_score
        )

        return round(coherence, 3)

    except Exception as e:
        print(f"Error computing coherence for answer: {answer[:50]}... -> {e}")
        return 0.1

def add_relevance_and_coherence_scores(input_excel_path, model_answer_path, output_excel_path):
    df_students = pd.read_excel(input_excel_path)

    with open(model_answer_path, "r", encoding="utf-8") as file:
        model_answers = json.load(file)

    model_answers_dict = {str(item["question_number"]): item["answer"] for item in model_answers}

    relevance_scores, coherence_scores = [], []

    for _, row in df_students.iterrows():
        q_no = str(row["Question Number"]).strip()
        answer = str(row["Answer"]).strip() if pd.notna(row["Answer"]) else ""

        if q_no in model_answers_dict:
            model_answer = model_answers_dict[q_no]

            tfidf_sim = compute_tfidf_cosine(answer, model_answer)
            jaccard_sim = jaccard_similarity(answer, model_answer)
            fuzzy_sim = fuzzy_score(answer, model_answer)
            relevance = relevance_score(tfidf_sim, jaccard_sim, fuzzy_sim)
            coherence = compute_spacy_coherence_score(answer)
        else:
            relevance = None
            coherence = None

        relevance_scores.append(relevance)
        coherence_scores.append(coherence)

    df_students["Relevance"] = relevance_scores
    df_students["Coherence"] = coherence_scores

    df_students.to_excel(output_excel_path, index=False)
    print(f"âœ… Relevance & Coherence scores added and saved to: {output_excel_path}")