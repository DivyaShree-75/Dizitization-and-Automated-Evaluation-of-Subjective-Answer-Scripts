# -*- coding: utf-8 -*-
"""text_parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pWak6AEaU2OLQOD-xUi0A1WNaNXJLXu8
"""

import json
import re
from typing import List, Tuple, Dict, Any

# Define patterns for identifying questions
question_patterns = [
    r'^\s*Q(?:uestion)?\s*[\d]+[.:]',  # e.g., "Q1:", "Question 2:"
    r'^\s*[\d]+\.\s'                   # e.g., "1. "
]

invalid_patterns = [
    r'Total', r'Marks', r'Score'  # Common non-question lines
]

def load_json(file_path: str) -> dict:
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def format_pages(pages: set) -> str:
    return ', '.join(map(str, sorted(pages)))

def match_pattern(pattern: str, text: str) -> bool:
    return re.search(pattern, text, re.IGNORECASE) is not None

def contains_invalid_pattern(text: str) -> bool:
    for pattern in invalid_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return True
    return False

def is_question(text: str) -> bool:
    for pattern in question_patterns:
        if match_pattern(pattern, text) and not contains_invalid_pattern(text):
            return True
    return False

def split_text_by_patterns(text: str) -> List[str]:
    # This can be customized based on actual text structure
    return re.split(r'\n+', text)

def extract_question_number(segment: str) -> str:
    match = re.search(r'Q(?:uestion)?\s*(\d+)|^(\d+)\.', segment, re.IGNORECASE)
    if match:
        return match.group(1) or match.group(2)
    return "Unknown"

def extract_answer_text(segment: str) -> str:
    # Remove the question number and return the rest as the start of the answer
    return re.sub(r'^\s*(Q(?:uestion)?\s*\d+|^\d+\.)\s*', '', segment, flags=re.IGNORECASE)

def extract_questions(text: str, page_no: int, last_question: str, last_answer: str, last_pages: set) -> Tuple[List[Dict[str, Any]], str, str, set]:
    questions = []
    current_question = last_question
    current_answer = last_answer
    page_numbers = last_pages

    segments = split_text_by_patterns(text)
    for segment in segments:
        if is_question(segment):
            if current_question:
                entry = {
                    "Question Number": current_question,
                    "Answer": current_answer.strip(),
                    "Pages": format_pages(page_numbers)
                }
                questions.append(entry)
            current_question = extract_question_number(segment)
            current_answer = extract_answer_text(segment)
            page_numbers = {page_no}
        else:
            current_answer += " " + segment.strip()
            page_numbers.add(page_no)

    return questions, current_question, current_answer, page_numbers

def process_json(file_path: str) -> List[Dict[str, Any]]:
    data = load_json(file_path)
    student_id = data["student_id"]
    all_questions = []
    last_question = None
    last_answer = ""
    last_pages = set()

    for page in data["pages"]:
        page_questions, last_question, last_answer, last_pages = extract_questions(
            page["text"], page["page_number"], last_question, last_answer, last_pages
        )
        for q in page_questions:
            q["StudentID"] = student_id
        all_questions.extend(page_questions)

    if last_question:
        final_entry = {
            "StudentID": student_id,
            "Question Number": last_question,
            "Answer": last_answer.strip(),
            "Pages": format_pages(last_pages)
        }
        all_questions.append(final_entry)

    return all_questions